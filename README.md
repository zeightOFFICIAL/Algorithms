# Algorithms
## Sorting
* <strong>Bubble sort</strong> - is the simplest sorting algorithm that works by repeatedly swapping the adjacent elements if they are in the wrong order. This algorithm is not suitable for large data sets as its average and worst-case time complexity is quite high. Comparison of neighbors (exchanging).
* <strong>Comb sort</strong> - is mainly an improvement over Bubble Sort. Comb Sort improves on Bubble Sort by using a gap of the size of more than 1. The gap starts with a large value and shrinks by a factor of 1.3 in every iteration until it reaches the value 1. Thus Comb Sort removes more than one inversion count with one swap and performs better than Bubble Sort. The shrink factor has been empirically found to be 1.3. Although it works better than Bubble Sort on average, worst-case remains O(n2). Comparison of numbers in intervals (exchange).
* <strong>Cocktail sort</strong> - is a variation of Bubble sort. Cocktail Sort traverses through a given array in both directions alternatively. Cocktail sort does not go through the unnecessary iteration making it efficient for large arrays. Comparison of neighbors (exchange).
* <strong>Insertion sort</strong> - is a simple sorting algorithm that works similar to the way you sort playing cards in your hands. The array is virtually split into a sorted and an unsorted part. Values from the unsorted part are picked and placed at the correct position in the sorted part. Comparison of neighbors (insertion).
* <strong>Shell sort</strong> - is mainly a variation of Insertion Sort. The idea of ShellSort is to allow the exchange of far items. In Shell sort, we make the array h-sorted for a large value of h. We keep reducing the value of h until it becomes 1. An array is said to be h-sorted if all sublists of every h’th element are sorted. Comparison of numbers in given sequences (exchange).
* <strong>Gnome sort</strong> - also called Stupid sort is based on the concept of a Garden Gnome sorting his flower pots. A garden gnome sorts the flower pots by the following method. He looks at the flower pot next to him and the previous one; if they are in the right order he steps one pot forward, otherwise he swaps them and steps one pot backwards. If there is no previous pot (he is at the starting of the pot line), he steps forwards; if there is no pot next to him (he is at the end of the pot line), he is done. Comparison of neighbors (insertion).
* <strong>Heap sort</strong> - is a comparison-based sorting technique based on Binary Heap data structure. It is similar to the selection sort where we first find the minimum element and place the minimum element at the beginning. Repeat the same process for the remaining elements. Heap sort is an in-place algorithm. Its typical implementation is not stable, but can be made stable. Typically 2-3 times slower than well-implemented QuickSort.  The reason for slowness is a lack of locality of reference. Comparison of heap summit and last element (exchange).
<br><br>https://www.geeksforgeeks.org/
## Hashing
* <strong>Adler-32</strong> - is a checksum algorithm written by Mark Adler in 1995, modifying Fletcher's checksum. Compared to a cyclic redundancy check of the same length, it trades reliability for speed (preferring the latter). Adler-32 is more reliable than Fletcher-16, and slightly less reliable than Fletcher-32. Implemented: adler32.
* <strong>Fowler–Noll–Vo</strong> - is a non-cryptographic hash function created by Glenn Fowler, Landon Curt Noll, and Kiem-Phong Vo. Implemented: fnv132, fnv164.
* <strong>Secure Hash Algorithm 1</strong> - is a cryptographically broken but still widely used hash function which takes an input and produces a 160-bit (20-byte) hash value known as a message digest – typically rendered as 40 hexadecimal digits. It was designed by the United States National Security Agency, and is a U.S. Federal Information Processing Standard. Implemented: sha1.
* <strong>Secure Hash Algorithm 2</strong> - is a set of cryptographic hash functions designed by the United States National Security Agency (NSA) and first published in 2001. They are built using the Merkle–Damgård construction, from a one-way compression function itself built using the Davies–Meyer structure from a specialized block cipher. SHA-2 includes significant changes from its predecessor, SHA-1. Implemented: sha256.
<br><br>https://en.wikipedia.org/
## Pattern search
* <strong>Bitap (exact)</strong> - is an exact string searching algorithm that was invented by Bálint Dömölki in 1964 and extended by R. K. Shyamasundar in 1977, before being reinvented by Ricardo Baeza-Yates and Gaston Gonnet in 1989 (one chapter of first author's PhD thesis) which also extended it to handle classes of characters, wildcards, and mismatches. In 1991, it was extended by Manber and Wu to handle also insertions and deletions (full fuzzy string searching). This algorithm was later improved by Baeza-Yates and Navarro in 1996.
* <strong>Boyer-Moore</strong> - is an efficient string-searching algorithm that is the standard benchmark for practical string-search literature. It was developed by Robert S. Boyer and J Strother Moore in 1977. The original paper contained static tables for computing the pattern shifts without an explanation of how to produce them. The algorithm for producing the tables was published in a follow-on paper; this paper contained errors which were later corrected by Wojciech Rytter in 1980.
* <strong>Knuth-Morris-Pratt</strong> - is a string-searching algorithm which searches for occurrences of a "word" W within a main "text string" S by employing the observation that when a mismatch occurs, the word itself embodies sufficient information to determine where the next match could begin, thus bypassing re-examination of previously matched characters.
* <strong>Rabin-Karp</strong> - is a string-searching algorithm created by Richard M. Karp and Michael O. Rabin (1987) that uses hashing to find an exact match of a pattern string in a text. It uses a rolling hash to quickly filter out positions of the text that cannot match the pattern, and then checks for a match at the remaining positions. Generalizations of the same idea can be used to find more than one match of a single pattern, or to find matches for more than one pattern.
* <strong>Naive</strong> - is a simple string-searching algorithm which compares text and pattern symbol by symbol.
<br><br>https://en.wikipedia.org/
## Shortest path on graph
* <strong>Dijkstra</strong> - is an algorithm for finding the shortest paths between nodes in a graph, which may represent, for example, road networks. It was conceived by computer scientist Edsger W. Dijkstra in 1956 and published three years later.
* <strong>Floyd-Warshall</strong> - is an algorithm for finding shortest paths in a directed weighted graph with positive or negative edge weights (but with no negative cycles). A single execution of the algorithm will find the lengths (summed weights) of shortest paths between all pairs of vertices. Although it does not return details of the paths themselves, it is possible to reconstruct the paths with simple modifications to the algorithm.
* <strong>Johnson</strong> -  is a way to find the shortest paths between all pairs of vertices in an edge-weighted directed graph. It allows some of the edge weights to be negative numbers, but no negative-weight cycles may exist. It works by using the Bellman–Ford algorithm to compute a transformation of the input graph that removes all negative weights, allowing Dijkstra's algorithm to be used on the transformed graph. It is named after Donald B. Johnson, who first published the technique in 1977.
<br><br>https://en.wikipedia.org/
## Minimum spanning tree on graph
* <strong>Kruskal</strong> - is algorithm which finds a minimum spanning forest of an undirected edge-weighted graph. If the graph is connected, it finds a minimum spanning tree. (A minimum spanning tree of a connected graph is a subset of the edges that forms a tree that includes every vertex, where the sum of the weights of all the edges in the tree is minimized. For a disconnected graph, a minimum spanning forest is composed of a minimum spanning tree for each connected component.) It is a greedy algorithm in graph theory as in each step it adds the next lowest-weight edge that will not form a cycle to the minimum spanning forest.
* <strong>Prim</strong> - is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. This means it finds a subset of the edges that forms a tree that includes every vertex, where the total weight of all the edges in the tree is minimized. The algorithm operates by building this tree one vertex at a time, from an arbitrary starting vertex, at each step adding the cheapest possible connection from the tree to another vertex.
* <strong>Reverse-Delete</strong> - is an algorithm in graph theory used to obtain a minimum spanning tree from a given connected, edge-weighted graph. It first appeared in Kruskal (1956), but it should not be confused with Kruskal's algorithm which appears in the same paper. If the graph is disconnected, this algorithm will find a minimum spanning tree for each disconnected part of the graph. The set of these minimum spanning trees is called a minimum spanning forest, which contains every vertex in the graph.
<br><br>https://en.wikipedia.org/
## Elementary
* <strong>Naive exponentiation</strong> - is a simple method to calculate the first number (base) to the power of the second number (power). It multiples the base and current result step by step, eventually approaching the solution.
* <strong>Squaring exponentiation</strong> - is a general method for fast computation of large positive integer powers of a number, or more generally of an element of a semigroup, like a polynomial or a square matrix.
---
* <strong>Naive summation</strong> - is the addition of a sequence of any kind of numbers, called addends or summands; the result is their sum or total. Beside numbers, other types of values can be summed as well: functions, vectors, matrices, polynomials and, in general, elements of any type of mathematical objects on which an operation denoted "+" is defined.
* <strong>Kahan summation</strong> - is used to minimize the loss of significance in the total result obtained by adding a sequence of finite-precision floating-point numbers. This is done by keeping a separate running compensation (a variable to accumulate small errors).
<br><br>https://www.geeksforgeeks.org/
<br>https://en.wikipedia.org/
## Theory of numbers
* <strong>Factorial</strong> - is the multiplication of all positive integers smaller than or equal to n. For example factorial of 6 is 6 * 5 * 4 * 3 * 2 * 1 which is 720. 
* <strong>Fibonacci</strong> - is a number sequence. 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, ... In mathematical terms, the sequence Fn of Fibonacci numbers is defined by the recurrence relation: F(n) = F(n-1) + F(n-2). Last number of the presented above sequence is calculated as follows 144 = 89 + 55. 
---
* <strong>Stein GCD</strong> - is an algorithm that computes the greatest common divisor of two non-negative integers. Stein’s algorithm replaces division with arithmetic shifts, comparisons, and subtraction.
* <strong>Euclidean GCD</strong> - is a way to find the greatest common divisor of two positive integers. GCD of two numbers is the largest number that divides both of them. A simple way to find GCD is to factorize both numbers and multiply common prime factors.
---
* <strong>Eratosthenes primes sieve</strong> - given a number n, print all primes smaller than or equal to n. It is also given that n is a small number. 
* <strong>Sundaram primes sieve</strong> - given a number n, print all primes smaller than or equal to n. Uses a different mapping method than Eratosthenes sieve.
---
* <strong>Borwein Pi</strong> - is an algorithm devised by Jonathan and Peter Borwein to calculate the value of 1/pi. They devised several other algorithms. They published the book Pi and the AGM – A Study in Analytic Number Theory and Computational Complexity.
* <strong>Chudnovsky Pi</strong> - is a fast method for calculating the digits of pi, based on Ramanujan’s pi formulae. It was published by the Chudnovsky brothers in 1988. It was used in the world record calculations of 2.7 trillion digits of pi in December 2009, 10 trillion digits in October 2011, 22.4 trillion digits in November 2016, 31.4 trillion digits in September 2018–January 2019, 50 trillion digits on January 29, 2020, 62.8 trillion digits on August 14, 2021, and 100 trillion digits on March 21, 2022.
* <strong>Gauss-Legendre Pi</strong> - is an algorithm to compute the digits of pi. It is notable for being rapidly convergent, with only 25 iterations producing 45 million correct digits of pi.
<br><br>https://www.geeksforgeeks.org/
<br>https://en.wikipedia.org/
## Applied
* <strong>Zeller Congruence</strong> - is an algorithm devised by Christian Zeller in the 19th century to calculate the day of the week for any Julian or Gregorian calendar date. It can be considered to be based on the conversion between Julian day and the calendar date.
* <strong>Meeus</strong> - is an algorithm for calculating the Julian Orthodox Easter day and Gregorian Orthodox Easter day (in between 1901..2099).
<br><br>https://en.wikipedia.org/